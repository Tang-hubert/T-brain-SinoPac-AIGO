{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install absl-py\n",
    "!pip install seaborn\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from absl import app, flags, logging\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, LeakyReLU, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'C:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\data\\training_data.csv')\n",
    "data_columns = {\n",
    "    'ID': 'ID',\n",
    "    '縣市': 'City',\n",
    "    '鄉鎮市區': 'District',\n",
    "    '路名': 'Street_Name',\n",
    "    '土地面積': 'Land_Area',\n",
    "    '使用分區': 'Zoning',\n",
    "    '移轉層次': 'Transfer_Level',\n",
    "    '總樓層數': 'Total_Floors',\n",
    "    '主要用途': 'Primary_Use',\n",
    "    '主要建材': 'Primary_Construction_Material',\n",
    "    '建物型態': 'Building_Type',\n",
    "    '屋齡': 'Age_of_Building',\n",
    "    '建物面積': 'Building_Area',\n",
    "    '車位面積': 'Parking_Area',\n",
    "    '車位個數': 'Number_of_Parking_Spaces',\n",
    "    '橫坐標': 'Longitude',\n",
    "    '縱坐標': 'Latitude',\n",
    "    '備註': 'Remarks',\n",
    "    '主建物面積': 'Main_Building_Area',\n",
    "    '陽台面積': 'Balcony_Area',\n",
    "    '附屬建物面積': 'Auxiliary_Building_Area',\n",
    "    '單價': 'Unit_Price'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_train:  0.43861284101460113\n",
      "MAE_train:  0.46650549311090966\n",
      "MSE_test:  0.4218248580717224\n",
      "MAE_test:  0.4565343122079575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# async def main_async():\n",
    "#     print('hi')\n",
    "\n",
    "def main():\n",
    "    # asyncio.run(main_async())\n",
    "\n",
    "    df = pd.read_csv(data_dir)\n",
    "    \n",
    "    df = df.rename(columns=data_columns)\n",
    "\n",
    "    df=df.drop([\"ID\", \"Longitude\",\"Latitude\", \"Street_Name\", \"Remarks\"], axis=1)\n",
    "    df['Address'] = df['City'] + df['District']\n",
    "    df = df.drop(columns=['City', 'District'])\n",
    "    # print(df.head)\n",
    "\n",
    "    # One hot encoding example\n",
    "    # df = pd.get_dummies(df, columns=['Primary_Use'])\n",
    "\n",
    "    # Label encoding\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Zoning'] = label_encoder.fit_transform(df['Zoning'])\n",
    "    Zoning_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    df['Primary_Use'] = label_encoder.fit_transform(df['Primary_Use'])\n",
    "    Primary_Use_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    df['Primary_Construction_Material'] = label_encoder.fit_transform(df['Primary_Construction_Material'])\n",
    "    Primary_Construction_Material_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    df['Building_Type'] = label_encoder.fit_transform(df['Building_Type'])\n",
    "    Building_Type_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    df['Address'] = label_encoder.fit_transform(df['Address'])\n",
    "    Address_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    # print(Zoning_mapping)\n",
    "\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    df['Land_Area'] = scaler.fit_transform(df['Land_Area'].values.reshape(-1, 1))\n",
    "    df['Age_of_Building'] = scaler.fit_transform(df['Age_of_Building'].values.reshape(-1, 1))\n",
    "    df['Building_Area'] = scaler.fit_transform(df['Building_Area'].values.reshape(-1, 1))\n",
    "    df['Parking_Area'] = scaler.fit_transform(df['Parking_Area'].values.reshape(-1, 1))\n",
    "    df['Main_Building_Area'] = scaler.fit_transform(df['Main_Building_Area'].values.reshape(-1, 1))\n",
    "    df['Balcony_Area'] = scaler.fit_transform(df['Balcony_Area'].values.reshape(-1, 1))\n",
    "    df['Auxiliary_Building_Area'] = scaler.fit_transform(df['Auxiliary_Building_Area'].values.reshape(-1, 1))\n",
    "    df['Unit_Price'] = scaler.fit_transform(df['Unit_Price'].values.reshape(-1, 1))\n",
    "\n",
    "    # to get each pairplot\n",
    "    # pairplot(df)\n",
    "\n",
    "    # shuffle\n",
    "    seed=5811\n",
    "    np.random.seed(seed)\n",
    "    dataset = df.values\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # seperate dataset\n",
    "    X = df.drop(columns=['Unit_Price'])\n",
    "    y = df['Unit_Price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "    # method\n",
    "    # train(X_train, X_test, y_train, y_test)\n",
    "    # call(X_test, y_test)\n",
    "\n",
    "    # Assuming X_train, Y_train, X_test, Y_test are your training and testing data\n",
    "    model = train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    pickle.dump(model, open(r'output\\output.pickle', \"wb\"))\n",
    "\n",
    "    # print(Y_pred)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def build_model():\n",
    "    model = MLPRegressor(hidden_layer_sizes=(32,), activation=\"relu\", solver=\"adam\", \n",
    "                         max_iter=80, random_state=42)\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(X_train, Y_train, X_test, Y_test):\n",
    "    model = build_model()\n",
    "    model.fit(X_train, Y_train)  # Fit the model with training data\n",
    "    \n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mae_train = mean_absolute_error(Y_train, Y_pred_train)\n",
    "    \n",
    "    print(\"MSE_train: \", mse_train)\n",
    "    print(\"MAE_train: \", mae_train)\n",
    "    \n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    mae_test = mean_absolute_error(Y_test, Y_pred_test)\n",
    "    \n",
    "    print(\"MSE_test: \", mse_test)\n",
    "    print(\"MAE_test: \", mae_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paitplot(df2):\n",
    "    res = df2[~df2.duplicated('City')]['City']\n",
    "    res = res.reset_index(drop=True)\n",
    "    print(res)\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        print(df2[df2['City'] == res[i]].shape)\n",
    "        plot = sns.pairplot(df2[df2['City'] == res[i]])\n",
    "        plot.savefig(f\"output/{res[i]}.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
