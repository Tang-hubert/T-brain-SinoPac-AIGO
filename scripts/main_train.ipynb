{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install absl-py\n",
    "!pip install seaborn\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from absl import app, flags, logging\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, LeakyReLU, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'C:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\data\\training_data.csv')\n",
    "data_columns = {\n",
    "    'ID': 'ID',\n",
    "    '縣市': 'City',\n",
    "    '鄉鎮市區': 'District',\n",
    "    '路名': 'Street_Name',\n",
    "    '土地面積': 'Land_Area',\n",
    "    '使用分區': 'Zoning',\n",
    "    '移轉層次': 'Transfer_Level',\n",
    "    '總樓層數': 'Total_Floors',\n",
    "    '主要用途': 'Primary_Use',\n",
    "    '主要建材': 'Primary_Construction_Material',\n",
    "    '建物型態': 'Building_Type',\n",
    "    '屋齡': 'Age_of_Building',\n",
    "    '建物面積': 'Building_Area',\n",
    "    '車位面積': 'Parking_Area',\n",
    "    '車位個數': 'Number_of_Parking_Spaces',\n",
    "    '橫坐標': 'Longitude',\n",
    "    '縱坐標': 'Latitude',\n",
    "    '備註': 'Remarks',\n",
    "    '主建物面積': 'Main_Building_Area',\n",
    "    '陽台面積': 'Balcony_Area',\n",
    "    '附屬建物面積': 'Auxiliary_Building_Area',\n",
    "    '單價': 'Unit_Price'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9400, 15) (2351, 15) (9400,) (2351,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [40]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\main_train.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# print(Y_pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\main_train.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape, X_test\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# method\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# train(X_train, X_test, y_train, y_test)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# call(X_test, y_test)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Assuming X_train, Y_train, X_test, Y_test are your training and testing data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m model \u001b[39m=\u001b[39m train_and_evaluate(X_train, y_train, X_test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(model, \u001b[39mopen\u001b[39m(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\\\u001b[39m\u001b[39moutput.pickle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\main_train.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     label_encoders[col] \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     X_train[col] \u001b[39m=\u001b[39m label_encoders[col]\u001b[39m.\u001b[39mfit_transform(X_train[col])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     X_test[col] \u001b[39m=\u001b[39m label_encoders[col]\u001b[39m.\u001b[39;49mtransform(X_test[col])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# unknown_label = -1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# for feature in categorical_cols:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#     # 检查测试集中的标签是否在训练集的标签中\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Create a pipeline with scaling, polynomial feature generation, and label encoding\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, ColumnTransformer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         transformers\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luke1/Desktop/projects/T-brain-SinoPac-AIGO/main_train.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[1;32mc:\\Users\\luke1\\Desktop\\projects\\T-brain-SinoPac-AIGO\\venv\\lib\\site-packages\\sklearn\\utils\\_encode.py:232\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    230\u001b[0m     diff \u001b[39m=\u001b[39m _check_unknown(values, uniques)\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m diff:\n\u001b[1;32m--> 232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(diff)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msearchsorted(uniques, values)\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [40]"
     ]
    }
   ],
   "source": [
    "# async def main_async():\n",
    "#     print('hi')\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(data_dir)\n",
    "    \n",
    "    df = df.rename(columns=data_columns)\n",
    "\n",
    "    df=df.drop([\"ID\", \"Longitude\",\"Latitude\", \"Street_Name\", \"Remarks\"], axis=1)\n",
    "    df['Address'] = df['City'] + df['District']\n",
    "    df = df.drop(columns=['City', 'District'])\n",
    "\n",
    "\n",
    "    # to get each pairplot\n",
    "    # pairplot(df)\n",
    "\n",
    "    # Label encoding\n",
    "    # from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # label_encoder = LabelEncoder()\n",
    "    # df['Zoning'] = label_encoder.fit_transform(df['Zoning'])\n",
    "    # Zoning_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    # df['Primary_Use'] = label_encoder.fit_transform(df['Primary_Use'])\n",
    "    # Primary_Use_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    # df['Primary_Construction_Material'] = label_encoder.fit_transform(df['Primary_Construction_Material'])\n",
    "    # Primary_Construction_Material_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    # df['Building_Type'] = label_encoder.fit_transform(df['Building_Type'])\n",
    "    # Building_Type_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    # df['Address'] = label_encoder.fit_transform(df['Address'])\n",
    "    # Address_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    \n",
    "    # print(Zoning_mapping)\n",
    "\n",
    "\n",
    "\n",
    "    # seperate dataset\n",
    "    X = df.drop(columns=['Unit_Price'])\n",
    "    y = df['Unit_Price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    # method\n",
    "    # train(X_train, X_test, y_train, y_test)\n",
    "    # call(X_test, y_test)\n",
    "\n",
    "    # Assuming X_train, Y_train, X_test, Y_test are your training and testing data\n",
    "    model = train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    pickle.dump(model, open(r'output\\output.pickle', \"wb\"))\n",
    "\n",
    "    # print(Y_pred)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_model():\n",
    "    model = MLPRegressor(hidden_layer_sizes=(64, 32), activation=\"relu\", solver=\"adam\", \n",
    "                         max_iter=1000, random_state=42, alpha=0.001)\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(X_train, Y_train, X_test, Y_test):\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Assuming X_train and X_test contain both numerical and categorical features\n",
    "\n",
    "    # Separate numerical and categorical columns\n",
    "    numerical_cols = ['Land_Area', 'Age_of_Building', 'Building_Area', 'Parking_Area', 'Main_Building_Area', 'Balcony_Area', 'Auxiliary_Building_Area']\n",
    "    categorical_cols = ['Zoning', 'Transfer_Level', 'Total_Floors', 'Primary_Use', 'Primary_Construction_Material', 'Building_Type', 'Number_of_Parking_Spaces', 'Address']\n",
    "\n",
    "    # Apply label encoding to categorical columns\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        X_train[col] = label_encoders[col].fit_transform(X_train[col])\n",
    "        X_test[col] = label_encoders[col].transform(X_test[col])\n",
    "\n",
    "    # unknown_label = -1\n",
    "    # for feature in categorical_cols:\n",
    "    #     # 检查测试集中的标签是否在训练集的标签中\n",
    "    #     unknown_labels = set(X_test[feature]) - set(label_encoders[feature].classes_)\n",
    "        \n",
    "    #     # 将未知标签映射为特定的未知标签值（例如，-1）\n",
    "    #     for label in unknown_labels:\n",
    "    #         X_test[feature][X_test[feature] == label] = unknown_label\n",
    "        \n",
    "    #     # 使用LabelEncoder进行转换\n",
    "    #     X_test[feature] = label_encoders[feature].transform(X_test[feature])\n",
    "\n",
    "    # Create a pipeline with scaling, polynomial feature generation, and label encoding\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_cols),\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False), numerical_cols),\n",
    "                ('cat', 'passthrough', categorical_cols)  # 'passthrough' indicates no transformation for categorical features\n",
    "            ])\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Fit and transform X_train using the pipeline\n",
    "    X_train_processed = pipeline.fit_transform(X_train)\n",
    "\n",
    "    # Transform X_test using the fitted pipeline\n",
    "    X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "\n",
    "    print(X_train_processed)\n",
    "\n",
    "\n",
    "    # build    \n",
    "    model = build_model()\n",
    "    model.fit(X_train_processed, Y_train)  # Fit the model with scaled training data\n",
    "    \n",
    "    Y_pred_train = model.predict(X_train_processed)\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    mae_train = mean_absolute_error(Y_train, Y_pred_train)\n",
    "    \n",
    "    print(\"MSE_train: \", mse_train)\n",
    "    print(\"MAE_train: \", mae_train)\n",
    "    \n",
    "    Y_pred_test = model.predict(X_test_processed)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    mae_test = mean_absolute_error(Y_test, Y_pred_test)\n",
    "    \n",
    "    print(\"MSE_test: \", mse_test)\n",
    "    print(\"MAE_test: \", mae_test)\n",
    "    \n",
    "    # Cross-Validation Score\n",
    "    cv_scores = cross_val_score(model, X_test_processed, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(\"Cross-Validation MSE: \", -np.mean(cv_scores))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paitplot(df2):\n",
    "    res = df2[~df2.duplicated('City')]['City']\n",
    "    res = res.reset_index(drop=True)\n",
    "    print(res)\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        print(df2[df2['City'] == res[i]].shape)\n",
    "        plot = sns.pairplot(df2[df2['City'] == res[i]])\n",
    "        plot.savefig(f\"output/{res[i]}.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
